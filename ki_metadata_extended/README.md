# Erweiterte KI-Metadaten-Analyse

Ein fortschrittliches System zur automatischen Bildanalyse mit KI-gestÃ¼tzter Metadatenextraktion.

## ğŸš€ Features

- **FastAPI Backend** mit DeepFace und CLIP Integration
- **Streamlit UI** mit interaktiver Zeitachsen-Ansicht und Statistiken
- **Neo4j Graph Database** fÃ¼r Metadaten-Speicherung
- **minIO** fÃ¼r skalierbare Bildspeicherung
- **Umfassendes Logging** von Uploads und Analysen
- **Robuste Fehlerbehandlung** und Validierung

## ğŸ› ï¸ Technologie-Stack

- **Backend**: FastAPI, Uvicorn
- **AI/ML**: DeepFace, CLIP (OpenAI), Transformers
- **Database**: Neo4j Graph Database
- **Storage**: minIO Object Storage
- **Frontend**: Streamlit, Plotly
- **Container**: Docker & Docker Compose

## ğŸ“‹ Voraussetzungen

- Docker und Docker Compose
- Mindestens 4GB RAM (fÃ¼r ML-Modelle)
- Internetverbindung (fÃ¼r initiale Modell-Downloads)

## ğŸš€ Installation & Start

1. **Repository klonen:**
```bash
git clone <repository-url>
cd ki_metadata_extended
```

2. **Services starten:**
```bash
docker-compose up --build
```

3. **Services sind verfÃ¼gbar unter:**
- **API Documentation**: http://localhost:8000/docs
- **Streamlit UI**: http://localhost:8501
- **Neo4j Browser**: http://localhost:7474 (neo4j / password)
- **minIO Console**: http://localhost:9001 (minioadmin / minioadmin)

## ğŸ“– API Verwendung

### Bild-Upload
```bash
curl -X POST "http://localhost:8000/upload/" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@your_image.jpg"
```

### Health Check
```bash
curl http://localhost:8000/health
```

### Logs abrufen
```bash
curl http://localhost:8000/logs/uploads
curl http://localhost:8000/logs/analysis
```

## ğŸ”§ Konfiguration

### Umgebungsvariablen
Die Standard-Konfiguration ist in `docker-compose.yml` definiert:

- **Neo4j**: neo4j/password
- **minIO**: minioadmin/minioadmin
- **Ports**: 8000 (API), 8501 (Streamlit), 7474 (Neo4j), 9001 (minIO)

### Daten-Persistierung
- Neo4j Daten: `./neo4j-data/`
- minIO Daten: `./minio-data/`
- Logs: `./logs/`

## ğŸ“Š FunktionalitÃ¤ten

### Bildanalyse
- **CLIP-basierte Bildklassifizierung** (Foto, Person, Performance)
- **DeepFace Gesichtsanalyse** (Alter, Geschlecht)
- **Automatische Metadatenextraktion**

### Visualisierung
- **Interaktive Timeline** der Analysen
- **Statistiken** zu Alters- und Geschlechterverteilung
- **Echtzeit-Updates** der Daten

### Datenmanagement
- **Graph-basierte Metadaten-Speicherung** in Neo4j
- **Skalierbare Bildspeicherung** in minIO
- **Umfassendes Logging** aller Operationen

## ğŸ› Troubleshooting

### HÃ¤ufige Probleme

1. **Port-Konflikte**: Stellen Sie sicher, dass die Ports 8000, 8501, 7474, 9001 frei sind
2. **Speicherplatz**: ML-Modelle benÃ¶tigen ~2GB Speicherplatz
3. **RAM**: Mindestens 4GB RAM fÃ¼r stabile Performance

### Logs Ã¼berprÃ¼fen
```bash
# Container-Logs
docker-compose logs app
docker-compose logs streamlit

# Anwendungs-Logs
docker-compose exec app cat /logs/analysis.log
docker-compose exec app cat /logs/uploads.log
```

## ğŸ”„ Entwicklung

### Lokale Entwicklung
```bash
# Dependencies installieren
pip install -r requirements.txt

# Services einzeln starten
docker-compose up neo4j minio
python -m uvicorn app.main:app --reload
streamlit run streamlit_app/main.py
```

### Code-Struktur
```
ki_metadata_extended/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI Application
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ process_image.py # Bildverarbeitung
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py        # Logging Utilities
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ main.py              # Streamlit UI
â”œâ”€â”€ docker-compose.yml       # Service-Konfiguration
â”œâ”€â”€ Dockerfile              # Container-Build
â””â”€â”€ requirements.txt        # Python Dependencies
```

## ğŸ“ Lizenz

Dieses Projekt ist fÃ¼r Bildungs- und Forschungszwecke konzipiert.

## ğŸ¤ Beitragen

1. Fork das Repository
2. Erstelle einen Feature-Branch
3. Committe deine Ã„nderungen
4. Push zum Branch
5. Erstelle einen Pull Request

## ğŸ“ Support

Bei Fragen oder Problemen erstellen Sie bitte ein Issue im Repository.
